{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-483 - Tarea 1: Neural Information Retrieval\n",
    "\n",
    "##### Juan Pablo Muñoz\n",
    "\n",
    "En esta tarea se implementa un flujo de procesos para la recuperación de información en texto. El corpus utilizado corresponde a Wall Street Journal 92, y se implementan Averaged Word Embeddings de skip-grams para la fase de recuperación. Finalmente, para rankear, se usa BM25.\n",
    "\n",
    "En un intento por mejorar la calidad de la recuperación, se propone evaluar las consultas sobre los títulos y los cuerpos de los documentos por separado, y combinar los resultados como se explica más adelante.\n",
    "\n",
    "Finalmente, se evalúa la calidad de la recuperación calculando las métricas de precision y recall en base a los datos provistos por el dataset y se concluye al respecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Índice Invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedIndex:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.index = dict()\n",
    "\n",
    "    def __contains__(self, item):\n",
    "        return item in self.index\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.index[item]\n",
    "\n",
    "    def add(self, word, docid):\n",
    "        if word in self.index:\n",
    "            if docid in self.index[word]:\n",
    "                self.index[word][docid] += 1\n",
    "            else:\n",
    "                self.index[word][docid] = 1\n",
    "        else:\n",
    "            d = dict()\n",
    "            d[docid] = 1\n",
    "            self.index[word] = d\n",
    "\n",
    "    #frequency of word in document\n",
    "    def get_document_frequency(self, word, docid):\n",
    "        if word in self.index:\n",
    "            if docid in self.index[word]:\n",
    "                return self.index[word][docid]\n",
    "            else:\n",
    "                raise LookupError('%s not in document %s' % (str(word), str(docid)))\n",
    "        else:\n",
    "            raise LookupError('%s not in index' % str(word))\n",
    "\n",
    "    #frequency of word in index, i.e. number of documents that contain word\n",
    "    def get_index_frequency(self, word):\n",
    "        if word in self.index:\n",
    "            return len(self.index[word])\n",
    "        else:\n",
    "            raise LookupError('%s not in index' % word)\n",
    "\n",
    "\n",
    "class DocumentLengthTable:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.table = dict()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.table)\n",
    "\n",
    "    def add(self, docid, length):\n",
    "        self.table[docid] = length\n",
    "\n",
    "    def get_length(self, docid):\n",
    "        if docid in self.table:\n",
    "            return self.table[docid]\n",
    "        else:\n",
    "            raise LookupError('%s not found in table' % str(docid))\n",
    "\n",
    "    def get_average_length(self):\n",
    "        sum = 0\n",
    "        for length in self.table.values():\n",
    "            sum += length\n",
    "        return float(sum) / float(len(self.table))\n",
    "\n",
    "\n",
    "def build_data_structures(corpus):\n",
    "    idx = InvertedIndex()\n",
    "    dlt = DocumentLengthTable()\n",
    "    for docid in corpus:\n",
    "\n",
    "        #build inverted index\n",
    "        for word in corpus[docid]:\n",
    "            idx.add(str(word), str(docid))\n",
    "\n",
    "        #build document length table\n",
    "        length = len(corpus[str(docid)])\n",
    "        dlt.add(docid, length)\n",
    "    return idx, dlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir generador de batches de entrenamiento\n",
    "\n",
    "Esta función lee un archivo desde el disco y va generando pares (skipgram, label) para entrenar la red neuronal de embedding de más adelante. Este método se descartó por no dar resultados satisfactorios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "import keras.preprocessing.sequence as seq\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def read_large_file(file_object):\n",
    "    \"\"\"\n",
    "    Uses a generator to read a large file lazily\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        data = file_object.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        yield data\n",
    "\n",
    "def batch_generator(batch_size):\n",
    "    while True:\n",
    "        couple_batch_word1 = []\n",
    "        couple_batch_word2 = []\n",
    "        label_batch = []\n",
    "        try:\n",
    "            with open(os.path.join('data', 'skipgrams_body.dataset'), 'r') as f:\n",
    "\n",
    "                    for line in read_large_file(f):\n",
    "                        if random.random() < 0.5: pass # tomar la mitad de las líneas al azar\n",
    "                        word1, word2, label = line.split(',')\n",
    "                        if int(label) == 0 and random.random() < 0.5: pass # 50% chance de no tomar un ejemplo negativo\n",
    "                        couple_batch_word1.append(int(word1))\n",
    "                        couple_batch_word2.append(int(word2))\n",
    "                        label_batch.append(int(label))\n",
    "                        if len(label_batch) >= batch_size:\n",
    "                            couple_batch_word1, couple_batch_word2, label_batch = shuffle(couple_batch_word1, couple_batch_word2, label_batch, random_state=0)\n",
    "                            couple_batch_word1_return = couple_batch_word1\n",
    "                            couple_batch_word2_return = couple_batch_word2\n",
    "                            label_batch_return = label_batch\n",
    "                            couple_batch_word1 = []\n",
    "                            couple_batch_word2 = []\n",
    "                            label_batch = []\n",
    "                            yield ([np.array(couple_batch_word1_return), np.array(couple_batch_word2_return)], np.array(label_batch_return))\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir constructor de skip-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.preprocessing.sequence as seq\n",
    "import numpy as np\n",
    "\n",
    "def skip_grams(sentences, window, vocab_size, nb_negative_samples=5.):\n",
    "\n",
    "    def sg(sentence):\n",
    "        return seq.skipgrams(sentence, vocab_size, window_size=window, negative_samples=nb_negative_samples)\n",
    "\n",
    "    couples = []\n",
    "    labels = []\n",
    "\n",
    "    for cpl, lbl in map(sg, sentences):\n",
    "        couples.extend(cpl)\n",
    "        labels.extend(lbl)\n",
    "        \n",
    "    return np.asarray(couples), np.asarray(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leer y parsear corpus Wall Street Journal '92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import json\n",
    "\n",
    "infile = open(os.path.join(\"data\",\"wsj2.xml\"),\"r\")\n",
    "contents = infile.read()\n",
    "soup = BeautifulSoup(contents,'lxml-xml')\n",
    "docs = soup.find_all('DOC')\n",
    "corpus = {}\n",
    "\n",
    "p = True\n",
    "for doc in docs:\n",
    "    docid = doc.DOCNO.string.strip()\n",
    "    head = doc.HL\n",
    "    head = head.string.strip()\n",
    "    body = doc.TEXT\n",
    "    body = body.get_text().strip()\n",
    "    corpus[docid] = {'head': head, 'body': body}\n",
    "    \n",
    "with open(os.path.join(\"data\",\"corpus.json\"), 'w') as outfile:\n",
    "    json.dump(corpus, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "with open(os.path.join(\"data\",\"corpus.json\")) as f:\n",
    "    corpus = json.load(f)\n",
    "#corpus_head: {doc_id: doc_headline}\n",
    "corpus_head = dict([(doc[0], doc[1]['head']) for doc in corpus.items()])\n",
    "#corpus_body: {doc_id: doc_body}\n",
    "corpus_body = dict([(doc[0], doc[1]['body']) for doc in corpus.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizar corpus\n",
    "\n",
    "En este punto se cargan por los títulos y los cuerpos en corpus separados. La idea es generar un embedding para cada corpus y luego evaluar las consultas por separado en cada uno.\n",
    "\n",
    "Para cada corpus:\n",
    "- Transformar tokens a minúsculas\n",
    "- Quitar tokens correspondientes a signos de puntuación, números y stopwords\n",
    "- Quitar tokens de longitud < 2 luego de los pasos anteriores\n",
    "- Quitar tokens con frecuencia = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño vocabulario corpus_head antes: 11990\n",
      "Tamaño vocabulario corpus_head después: 11990\n",
      "Tamaño vocabulario corpus_body antes: 59349\n",
      "Tamaño vocabulario corpus_body después: 59349\n"
     ]
    }
   ],
   "source": [
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "remove_terms = punctuation + '0123456789'\n",
    "\n",
    "# Normalizar corpus_head\n",
    "for doc_id, doc_head in corpus_head.items():\n",
    "    clean_head = [word.lower() for word in tokenizer.tokenize(doc_head) if word.lower() not in remove_terms]\n",
    "    clean_head = [tok_sent for tok_sent in clean_head if tok_sent not in stop_words]\n",
    "    clean_head = [tok_sent for tok_sent in clean_head if len(' '.join(tok_sent).split()) >= 2]\n",
    "    corpus_head[doc_id] = clean_head\n",
    "\n",
    "# Obtener frecuencias de palabras post-limpieza\n",
    "freq_head_pre = collections.Counter([token for doc_id, doc_head in corpus_head.items() for token in doc_head])   \n",
    "print('Tamaño vocabulario corpus_head antes:', len(freq_head_pre))\n",
    "\n",
    "# última pasada para eliminar palabras poco frecuentes\n",
    "min_freq_head = 0\n",
    "for doc_id, doc_head in corpus_head.items():\n",
    "    clean_head = [token for token in doc_head if freq_head_pre[token] > min_freq_head]\n",
    "    corpus_head[doc_id] = clean_head   \n",
    "\n",
    "freq_head_post = collections.Counter([token for doc_id, doc_head in corpus_head.items() for token in doc_head])   \n",
    "print('Tamaño vocabulario corpus_head después:', len(freq_head_post))\n",
    "    \n",
    "# Normalizar corpus_body\n",
    "for doc_id, doc_body in corpus_body.items():\n",
    "    clean_body = [word.lower() for word in tokenizer.tokenize(doc_body) if word.lower() not in remove_terms]\n",
    "    clean_body = [tok_sent for tok_sent in clean_body if tok_sent not in stop_words]\n",
    "    clean_body = [tok_sent for tok_sent in clean_body if len(' '.join(tok_sent).split()) > 2]\n",
    "    corpus_body[doc_id] = clean_body\n",
    "    \n",
    "# Obtener frecuencias de palabras post-limpieza\n",
    "freq_body_pre = collections.Counter([token for doc_id, doc_body in corpus_body.items() for token in doc_body])   \n",
    "print('Tamaño vocabulario corpus_body antes:', len(freq_body_pre))\n",
    "\n",
    "# última pasada para eliminar palabras poco frecuentes\n",
    "min_freq_body = 0\n",
    "for doc_id, doc_body in corpus_body.items():\n",
    "    clean_body = [token for token in doc_body if freq_body_pre[token] > min_freq_body]\n",
    "    corpus_body[doc_id] = clean_body   \n",
    "\n",
    "freq_body_post = collections.Counter([token for doc_id, doc_body in corpus_body.items() for token in doc_body])      \n",
    "print('Tamaño vocabulario corpus_body después:', len(freq_body_post))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comprobar que los corpus se cargaron y normalizaron correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['notice', 'readers']\n",
      "['concerning', 'move', 'nice', 'yeltsin', 'better', 'judith', 'valente', 'staff', 'reporter', 'wall', 'street', 'journal']\n",
      "['workplace', 'firms', 'train', 'bridge', 'still', 'laura', 'castro', 'staff', 'reporter', 'wall', 'street', 'journal']\n",
      "['tucson', 'electric', 'power', 'creditors', 'fail', 'bid', 'force', 'utility', 'chapter', 'frederick', 'rose', 'staff', 'reporter', 'wall', 'street', 'journal']\n",
      "['technology', 'healthcare', 'new', 'york', 'request', 'rates', 'rejected']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for id, doc in corpus_head.items():\n",
    "    print(doc)\n",
    "    count +=1\n",
    "    if count > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['early', 'last', 'year', 'costa', 'wrote', 'gorbachev', 'seeking', 'donation', 'wartime', 'artillery', 'fledgling', 'wisconsin', 'military', 'history', 'museum', 'costa', 'promised', 'whatever', 'soviet', 'leader', 'sent', 'would', 'displayed', 'elements', 'away', 'vandals', 'exchange', 'offered', 'send', 'gorbachev', 'wisconsin', 'cheese', 'sausage', 'beer', 'cherry', 'wine', 'costa', 'great', 'surprise', 'gorbachev', 'responded', 'enthusiastically', 'ordered', 'defense', 'aides', 'scour', 'soviet', 'arsenal', 'world', 'war', 'tank', 'could', 'sent', 'museum', 'settled', 'model', 'russian', 'diplomat', 'calls', 'sacred', 'machine', 'saved', 'many', 'lives', 'war', 'gorbachev', 'ordered', 'tank', 'shipped', 'plant', 'ukraine', 'seven', 'mechanics', 'worked', 'three', 'months', 'restoring', 'folks', 'wisconsin', 'waited', 'tank', 'gorbachev', 'running', 'trouble', 'home', 'including', 'august', 'coup', 'thought', 'would', 'end', 'costa', 'says', 'still', 'plans', 'send', 'tank', 'somehow', 'moved', 'ahead', 'oct', 'intricate', 'negotiations', 'state', 'department', 'customs', 'service', 'bureau', 'alcohol', 'tobacco', 'firearms', 'fully', 'restored', 'arrived', 'port', 'milwaukee', 'elated', 'costa', 'immediately', 'hopped', 'onto', 'waving', 'soviet', 'flags', 'first', 'russian', 'tank', 'reach', 'american', 'soil', 'come', 'peace', 'says', 'costa', 'pentagon', 'taken', 'asked', 'tank', 'placed', 'display', 'patton', 'museum', 'armor', 'fort', 'knox', 'among', 'museums', 'tank', 'permanent', 'home', 'wisconsin', 'museum', 'completed', 'yuri', 'russian', 'attache', 'washington', 'says', 'gorbachev', 'saw', 'project', 'way', 'reach', 'ordinary', 'american', 'citizens', 'soviet', 'officials', 'also', 'promised', 'costa', 'meeting', 'gorbachev', 'kind', 'air', 'costa', 'says']\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for id, doc in corpus_body.items():\n",
    "    print(doc)\n",
    "    count +=1\n",
    "    if count > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear Índices Invertidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_head, dlt_head = build_data_structures(corpus_head)\n",
    "idx_body, dlt_body = build_data_structures(corpus_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920102-0016': 2,\n",
       " 'WSJ920107-0148': 1,\n",
       " 'WSJ920109-0168': 1,\n",
       " 'WSJ920116-0165': 1,\n",
       " 'WSJ920122-0092': 1,\n",
       " 'WSJ920211-0055': 1,\n",
       " 'WSJ920212-0133': 1,\n",
       " 'WSJ920218-0033': 1,\n",
       " 'WSJ920219-0141': 1,\n",
       " 'WSJ920219-0071': 1,\n",
       " 'WSJ920220-0137': 1,\n",
       " 'WSJ920220-0115': 1,\n",
       " 'WSJ920227-0117': 1,\n",
       " 'WSJ920302-0142': 1,\n",
       " 'WSJ920303-0101': 1,\n",
       " 'WSJ920313-0027': 1,\n",
       " 'WSJ920320-0104': 2}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_head['man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlt_head.get_length('WSJ920102-0016')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920106-0058': 1,\n",
       " 'WSJ920122-0020': 1,\n",
       " 'WSJ920127-0006': 1,\n",
       " 'WSJ920129-0119': 1,\n",
       " 'WSJ920203-0061': 1,\n",
       " 'WSJ920203-0021': 1,\n",
       " 'WSJ920203-0175': 1,\n",
       " 'WSJ920204-0104': 1,\n",
       " 'WSJ920205-0021': 1,\n",
       " 'WSJ920206-0179': 1,\n",
       " 'WSJ920206-0005': 1,\n",
       " 'WSJ920207-0051': 1,\n",
       " 'WSJ920211-0018': 1,\n",
       " 'WSJ920212-0152': 1,\n",
       " 'WSJ920228-0036': 1,\n",
       " 'WSJ920302-0040': 1,\n",
       " 'WSJ920303-0052': 1,\n",
       " 'WSJ920319-0072': 1,\n",
       " 'WSJ920320-0006': 1}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_body['completes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlt_body.get_length('WSJ920304-0010')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crear embedder de términos\n",
    "Para cada corpus:\n",
    "- Crear skip-grams para entrenamiento\n",
    "- Entrenar embedder\n",
    "- Obtener y almacenar Averaged Word Embeddings de documentos en el corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hacer encoding del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label encodings: demoró 81 [s]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Label encoding\n",
    "from sklearn import preprocessing\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# flat_list = [item for sublist in l for item in sublist]\n",
    "\n",
    "le_head = preprocessing.LabelEncoder()\n",
    "le_head.fit([word for doc in corpus_head.values() for word in doc])\n",
    "\n",
    "le_body = preprocessing.LabelEncoder()\n",
    "le_body.fit([word for doc in corpus_body.values() for word in doc])\n",
    "\n",
    "encoded_heads = [le_head.transform(head) for head in corpus_head.values() if len(head) > 0]\n",
    "encoded_bodies = [le_body.transform(body) for body in corpus_body.values() if len(body) > 0]\n",
    "\n",
    "print('label encodings: demoró {} [s]'.format(round(time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generar skip-grams a partir del corpus_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# Head\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Tamaño de vocabulario\n",
    "# idx_corpus.index: {word1: [doc1,...]}\n",
    "\n",
    "corpus_head_vocab_size = len(idx_head.index.keys())\n",
    "\n",
    "# Tamaño de la ventana\n",
    "corpus_head_window_size = 3. # <- Configurado arbitariamente\n",
    "\n",
    "# Cantidad de ejemplos negativos versus positivos\n",
    "corpus_head_negative_samples = 3 # <- Configurado arbitariamente\n",
    "\n",
    "# Crear skip-grams\n",
    "# skip_grams(sentences, window, vocab_size, nb_negative_samples=5.)\n",
    "\n",
    "couples_head, labels_head = skip_grams(\n",
    "    sentences=encoded_heads,\n",
    "    window=corpus_head_window_size,\n",
    "    vocab_size=corpus_head_vocab_size,\n",
    "    nb_negative_samples=corpus_head_negative_samples,\n",
    ")\n",
    "\n",
    "print('skip-grams de corpus_head: demoró {} [s]'.format(round(time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generar skip-grams a partir del corpus_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pickle\n",
    "\n",
    "# Body\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# función auxiliar para particionar conjunto de documentos\n",
    "def split(a, n):\n",
    "    k, m = divmod(len(a), n)\n",
    "    return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
    "\n",
    "# Tamaño de vocabulario\n",
    "# idx_corpus.index: {word1: [doc1,...]}\n",
    "\n",
    "corpus_body_vocab_size = len(idx_body.index.keys())\n",
    "\n",
    "# Tamaño de la ventana\n",
    "corpus_body_window_size = 5 # <- Configurado arbitariamente\n",
    "\n",
    "# Cantidad de ejemplos negativos versus positivos\n",
    "corpus_body_negative_samples = 3. # <- Configurado arbitariamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10% de skip-grams construidos\n",
      "20% de skip-grams construidos\n",
      "30% de skip-grams construidos\n",
      "40% de skip-grams construidos\n",
      "50% de skip-grams construidos\n",
      "60% de skip-grams construidos\n",
      "70% de skip-grams construidos\n",
      "80% de skip-grams construidos\n",
      "90% de skip-grams construidos\n",
      "100% de skip-grams construidos\n",
      "skip-grams de corpus_body: demoró 599 [s]\n"
     ]
    }
   ],
   "source": [
    "# Crear skip-grams\n",
    "# skip_grams(sentences, window, vocab_size, nb_negative_samples=5.)\n",
    "\n",
    "n_partitions = 10 # <- Generar skip-grams en particiones, ojalá resulte\n",
    "couples_body = []\n",
    "labels_body = []\n",
    "count = 0\n",
    "\n",
    "for encoded_bodies_partition in list(split(encoded_bodies, n_partitions)):\n",
    "    couples_body_part, labels_body_part = skip_grams(\n",
    "        sentences=encoded_bodies_partition,\n",
    "        window=corpus_body_window_size,\n",
    "        vocab_size=corpus_body_vocab_size,\n",
    "        nb_negative_samples=corpus_body_negative_samples,\n",
    "    )\n",
    "    #couples_body.extend(couples_body_part)\n",
    "    #labels_body.extend(labels_body_part)\n",
    "    count += 1\n",
    "    with open(os.path.join('data', 'skipgrams_body.dataset'), 'a+') as f:\n",
    "        #cada linea será: couple[0],couple[1],label\n",
    "        for couple, label in zip(couples_body_part, labels_body_part):\n",
    "            f.write(str(couple[0])+','+str(couple[1])+','+str(label)+'\\n')\n",
    "    \n",
    "    print('{}% de skip-grams construidos'.format(int(100/n_partitions)*count))\n",
    "\n",
    "print('skip-grams de corpus_body: demoró {} [s]'.format(round(time.time()-start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir y entrenar embedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Activation, Flatten, Reshape, Dense\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_epoch = 10\n",
    "body_datapoints_per_word = int(2*corpus_body_window_size*(corpus_body_negative_samples + 1))\n",
    "body_batch_size = int(body_datapoints_per_word*100)\n",
    "vec_dim = 256\n",
    "body_samples_per_epoch = int(corpus_body_vocab_size*body_datapoints_per_word/body_batch_size)*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (4000, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (4000, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (4000, 1, 256)       6539264     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (4000, 1, 256)       6539264     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (4000, 256)          0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (4000, 256)          0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (4000, 512)          0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (4000, 1)            513         concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (4000, 1)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 13,079,041\n",
      "Trainable params: 13,079,041\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/10\n",
      "12750/12750 [==============================] - 280s 22ms/step - loss: 0.1011 - acc: 0.8657\n",
      "Epoch 2/10\n",
      "12750/12750 [==============================] - 278s 22ms/step - loss: 0.0986 - acc: 0.8679\n",
      "Epoch 3/10\n",
      "11365/12750 [=========================>....] - ETA: 30s - loss: 0.0976 - acc: 0.8688 ETA: 30s - loss: 0.0976 - acc"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-1dfeeb8ab443>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mmodel_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mse'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mmodel_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0mmodel_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody_batch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbody_samples_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1418\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1420\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1217\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1218\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "keras.backend.clear_session()\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "\n",
    "input_pvt = Input(batch_shape=(body_batch_size, 1), dtype='int32')\n",
    "input_ctx = Input(batch_shape=(body_batch_size, 1), dtype='int32')\n",
    "embedded_pvt = Embedding(input_dim=corpus_body_vocab_size, output_dim=vec_dim, input_length=1)(input_pvt)\n",
    "flattened_embedded_pvt = Flatten()(embedded_pvt)\n",
    "embedded_ctx = Embedding(input_dim=corpus_body_vocab_size, output_dim=vec_dim, input_length=1)(input_ctx)\n",
    "flattened_embedded_ctx = Flatten()(embedded_ctx)\n",
    "#merged = Concatenate([embedded_pvt, embedded_ctx], mode='concat', output_shape=(body_batch_size, 1))\n",
    "merged = Concatenate()([flattened_embedded_pvt, flattened_embedded_ctx])\n",
    "#flattened = Flatten()(merged)\n",
    "dense = Dense(1)(merged)\n",
    "predictions = Activation('sigmoid')(dense)\n",
    "model_body = Model(inputs=[input_pvt, input_ctx], outputs=predictions)\n",
    "model_body.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "model_body.summary()\n",
    "model_body.fit_generator(generator=batch_generator(body_batch_size), steps_per_epoch=body_samples_per_epoch, epochs=nb_epoch, verbose=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión sobre el método manual de creación de embeddings\n",
    "\n",
    "Crear embeddings de términos con el enfoque y arquitectura anterior es infructuoso. El accuracy alcanzado no supera al de realizar elecciones al azar, a pesar de haber probado muchas variaciones en arquitectura y en el proceso de entrenamiento: tamaño de vector de embedding iguales a 64, 128 y 256; haciendo subsampling negativo, cantidad de pasos por epoch, tamaños de batch y cantidad de epochs totales.\n",
    "\n",
    "Se sospecha que el modelo anterior no logra aprender de los ejemplos, ya que el ni loss no disminuye en ningún momento durante el entrenamiento. Esto podría resolverse ajustando el learning rate del modelo, y disminuyendo la proporción de ejemplos negativos versus positivos.\n",
    "\n",
    "Crear y gestionar el gran dataset de skip-grams fue complicado debido a su gran tamaño. Se tuvo que escribir a un archivo en disco a medida que se generaban los ejemplos de entrenamiento, y luego, se tuvo que crear una función generadora que entregara batches de ejemplos desde ese archivo para el entrenamiento. Estas tareas tomaron bastante tiempo y esfuerzo para programar de manera de no sobrepasar la capacidad de memoria principal del computador con el que se trabaja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cambio de metodología: usar Gensim\n",
    "\n",
    "Gensim ofrece implementaciones optimizadas para la creación de skip-gram term embeddings y otras utilidades relevantes para esta tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear term embeddings para el corpus body\n",
    "\n",
    "Parámetros:\n",
    "- Embedding size: 256\n",
    "- Window size: 5\n",
    "- Negative sampling (ejemplos negativos por cada ejemplo positivo): 5 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19482320, 20645420)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "\n",
    "model_body = Word2Vec(corpus_body.values(), size=256, window=5, workers=4, sg=1, compute_loss=True)\n",
    "model_body.train(corpus_body.values(), total_examples=len(corpus_body.values()), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('funds', 0.4545094668865204),\n",
       " ('ibc', 0.41579580307006836),\n",
       " ('laundering', 0.4112887680530548),\n",
       " ('launderers', 0.40672963857650757),\n",
       " ('wittbrodt', 0.4031805694103241),\n",
       " ('firas', 0.4000621438026428),\n",
       " ('inflow', 0.39657074213027954),\n",
       " ('deposited', 0.39371025562286377),\n",
       " ('birinyi', 0.3909085690975189),\n",
       " ('accrue', 0.39081132411956787)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_body.wv.most_similar(positive=['money'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear term embeddings para el corpus head\n",
    "\n",
    "Parámetros:\n",
    "- Embedding size: 64 (menor vocabulario y menor tamaño de corpus -> menor tamaño de embedding)\n",
    "- Window size: 2\n",
    "- Negative sampling (ejemplos negativos por cada ejemplo positivo): 5 (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(673093, 1011060)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_head = Word2Vec(corpus_head.values(), size=64, window=3, workers=4, sg=1, compute_loss=True)\n",
    "model_head.train(corpus_head.values(), total_examples=len(corpus_head.values()), epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de creación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\gensim\\matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int32 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('profiting', 0.850208580493927),\n",
       " ('key', 0.7676757574081421),\n",
       " ('changing', 0.7649471163749695),\n",
       " ('raising', 0.7578659057617188),\n",
       " ('interest', 0.7559293508529663),\n",
       " ('low', 0.7543566226959229),\n",
       " ('lindley', 0.7482011318206787),\n",
       " ('matters', 0.740726888179779),\n",
       " ('bet', 0.7368081212043762),\n",
       " ('mortgages', 0.7363840341567993)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_head.wv.most_similar(positive=['money'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.18567146, -0.02153717,  0.06885374,  0.03297263,  0.3131142 ,\n",
       "        0.08975619, -0.11052741,  0.19241533,  0.11680879,  0.06733435,\n",
       "        0.26860726,  0.05023226, -0.1991347 ,  0.18392667,  0.13218778,\n",
       "       -0.08467516, -0.02753326,  0.03503089,  0.03599699, -0.4228239 ,\n",
       "       -0.26320893, -0.11794525,  0.11193211, -0.1082921 ,  0.0407163 ,\n",
       "       -0.0542684 , -0.11404806, -0.06996501,  0.2504337 ,  0.18256629,\n",
       "       -0.06491038, -0.072845  ,  0.20264314,  0.41007587, -0.04655646,\n",
       "        0.01319878,  0.16538344, -0.24558426,  0.2575402 ,  0.20509824,\n",
       "       -0.26845592,  0.14231493, -0.06436489, -0.21730053,  0.45237666,\n",
       "       -0.21092172, -0.12708688, -0.36677432,  0.05865473, -0.1540093 ,\n",
       "       -0.09489243,  0.12610103,  0.06323103, -0.03468376,  0.01689659,\n",
       "        0.25000334, -0.11046371,  0.18169317,  0.18925476, -0.08350138,\n",
       "       -0.18891333, -0.08228879, -0.05616997,  0.08851402], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_head.wv['crisis']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargar consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "with open(os.path.join('data', 'topics.51-100_'), 'r') as f:\n",
    "    queries = {}\n",
    "    for line in f.readlines():\n",
    "        if '<num> Number:' in line:\n",
    "            query_id = int(line.strip('<num> Number: ').strip('\\n'))\n",
    "        if '<title> Topic:' in line:\n",
    "            q = line.strip('<title> Topic: ').strip('\\n')\n",
    "            queries[query_id] = q\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud en la lectura de las consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Airbus Subsidies'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizar sobre las consultas mismo proceso de limpieza que a los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import collections\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "    \n",
    "remove_terms = punctuation + '0123456789'\n",
    "\n",
    "normalized_queries = dict()\n",
    "\n",
    "# Normalizar queries\n",
    "token_min_len = 1\n",
    "for q_id, q in queries.items():\n",
    "    clean_q = [word.lower() for word in tokenizer.tokenize(q) if word.lower() not in remove_terms]\n",
    "    clean_q = [tok_sent for tok_sent in clean_q if tok_sent not in stop_words]\n",
    "    clean_q = [tok_sent for tok_sent in clean_q if len(tok_sent) > query_min_freq]\n",
    "    normalized_queries[q_id] = clean_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de normalización de las consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['airbus', 'subsidies']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_queries[51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener lista de documentos candidatos a relevantes dada una consulta y un índice invertido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idx_head, dlt_head\n",
    "#idx_body, dlt_body\n",
    "\n",
    "def get_doc_list(q, idx):\n",
    "    doc_id_list = []\n",
    "    for word in q:\n",
    "        doc_id_list.extend(list(idx[word].keys()))\n",
    "    return list(set(doc_id_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtener Averaged Word Embedding dada una consulta y un embedder\n",
    "- Palabras de la consulta que no estén en el vocabulario del embedder, se quitan\n",
    "- Si ninguna de las palabras en la consulta están en el vocabulario, retornar vector de ceros (nota: esta decisión se tomó de forma arbitraria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def awe(doc, w2v):\n",
    "    d_post = [term for term in doc if term in w2v.wv.vocab]\n",
    "    #if len(list(set(doc) - set(d_post))) != 0: print('Palabras fuera del vocabulario:', list(set(doc) - set(d_post)))\n",
    "    # si ninguna palabra de la consulta estaba en el vocabulario, retornar vector nulo\n",
    "    if len(d_post) == 0: return np.zeros(len(w2v.wv[list(w2v.wv.vocab.keys())[0]]))\n",
    "    # vector de cada término dividido en su módulo\n",
    "    term_vectors = np.array([w2v.wv[term]/norm(w2v.wv[term]) for term in d_post])\n",
    "    # se suman en un solo vector\n",
    "    v = sum(term_vectors)\n",
    "    # y se divide por la cantidad de palabras en la consulta (post eliminación de aquellas ausentes en el vocabulario)\n",
    "    v = v/len(d_post)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crear función de similitud coseno entre term embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(v1, v2):\n",
    "    assert v1.size == v2.size\n",
    "    return np.dot(v1/norm(v1),v2/norm(v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear funcionamiento de función de similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3394552"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(model_body.wv['canada'], model_body.wv['australia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5398009"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim(model_head.wv['money'], model_head.wv['poor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud del constructor de AWEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.03421513,  0.00891455, -0.02225829, -0.07041164,  0.20219119,\n",
       "       -0.08714882, -0.02772672, -0.02434807, -0.04656893,  0.11163279,\n",
       "        0.1304579 ,  0.06697559, -0.09622457, -0.00749928,  0.03979254,\n",
       "        0.04682301, -0.08996513,  0.04634939,  0.12648556, -0.12847096,\n",
       "       -0.03478785, -0.02540919,  0.06086544,  0.01533053, -0.02580533,\n",
       "       -0.0261116 , -0.02289065,  0.10325227,  0.10931162, -0.0808276 ,\n",
       "       -0.10290595,  0.06468564,  0.03423164,  0.24201924,  0.04245242,\n",
       "       -0.13983841,  0.13245203, -0.00992088,  0.0516552 ,  0.1057655 ,\n",
       "       -0.00293422,  0.06102055, -0.02226912, -0.1438515 ,  0.2279933 ,\n",
       "       -0.05950605, -0.10459995, -0.25676426,  0.01612249, -0.11389931,\n",
       "        0.01852683,  0.06698634,  0.07983918, -0.110659  ,  0.04674634,\n",
       "        0.08703631,  0.01364428,  0.0887432 , -0.02945945,  0.00878621,\n",
       "       -0.0267818 , -0.1130468 , -0.00357049,  0.08234187], dtype=float32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awe(normalized_queries[-1], model_head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluar consultas en corpus\n",
    "\n",
    "- Para cada consulta:\n",
    "    - recuperar doc_ids de los candidatos a relevantes desde el Índice invertido del corpus\n",
    "    - calcular similitud entre AWE(consulta) y AWE(documento) para cada documento en los candidatos a relevantes\n",
    "    - retornar los doc_ids de los 50 documentos más similares a la consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_queries(q_dict, corpus, idx, w2v):\n",
    "    candidates_to_be_rel = []\n",
    "    for q in q_dict.values():\n",
    "        for term in q:\n",
    "            if term in idx:\n",
    "                candidates_to_be_rel.extend([doc_id for doc_id, term_freq in idx[term].items()])\n",
    "    candidates_to_be_rel = list(set(candidates_to_be_rel))\n",
    "    \n",
    "    # computar AWE de documentos candidatos a relevantes\n",
    "    awe_docs = []\n",
    "    for doc_id in candidates_to_be_rel:\n",
    "            awe_docs.append(awe(corpus[doc_id], w2v))\n",
    "    \n",
    "    # Comparar AWE de cada query con los AWE de los documentos candidatos\n",
    "    query_rels = dict()\n",
    "    for q_id, q in q_dict.items():\n",
    "        query_rels[q_id] = dict()\n",
    "        for awe_doc, doc_id in zip(awe_docs, candidates_to_be_rel):\n",
    "            awe_q = awe(q, w2v)\n",
    "            query_rels[q_id][doc_id] = sim(awe_q, awe_doc)\n",
    "\n",
    "    return query_rels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "eval_queries_head = eval_queries(normalized_queries, corpus_head, idx_head, model_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "eval_queries_body = eval_queries(normalized_queries, corpus_body, idx_body, model_body)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de cálculo de medidas de similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920310-0144': 0.6183162,\n",
       " 'WSJ920128-0124': 0.7699244,\n",
       " 'WSJ920204-0151': 0.7595831,\n",
       " 'WSJ920226-0129': 0.782719,\n",
       " 'WSJ920323-0110': 0.83635914,\n",
       " 'WSJ920212-0065': 0.8541875,\n",
       " 'WSJ920203-0053': 0.8955887,\n",
       " 'WSJ920113-0031': 0.8684391,\n",
       " 'WSJ920219-0094': 0.76710755,\n",
       " 'WSJ920106-0064': 0.5371995}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(eval_queries_head[51].items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920204-0151': 0.40141845,\n",
       " 'WSJ920128-0124': 0.4434378,\n",
       " 'WSJ920220-0054': 0.40581065,\n",
       " 'WSJ920304-0083': 0.4648237,\n",
       " 'WSJ920316-0040': 0.3737756,\n",
       " 'WSJ920219-0094': 0.43492016,\n",
       " 'WSJ920210-0101': 0.49381793,\n",
       " 'WSJ920310-0049': 0.4232899,\n",
       " 'WSJ920313-0142': 0.4130813,\n",
       " 'WSJ920303-0064': 0.36430573}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(eval_queries_body[51].items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función para obtener los n documentos más similares a cada consulta, en el espacio de los embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n(qrels, n=50):\n",
    "    top_n_qrels = {}\n",
    "    for q_id, rels in qrels.items():\n",
    "        top_n_qrels[q_id] = dict(sorted(rels.items(), key=lambda x: -x[1])[:n])\n",
    "    return top_n_qrels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtener top-50 documentos más similares a cada consulta, para ambos corpus_head y corpus_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_queries_head_top_50 = get_top_n(eval_queries_head, n=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_queries_body_top_50 = get_top_n(eval_queries_body, n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud del paso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920124-0156': 0.9633757,\n",
       " 'WSJ920204-0124': 0.94442385,\n",
       " 'WSJ920323-0142': 0.93776816,\n",
       " 'WSJ920218-0041': 0.9376886,\n",
       " 'WSJ920316-0121': 0.9365615,\n",
       " 'WSJ920115-0023': 0.93163246,\n",
       " 'WSJ920130-0145': 0.9306904,\n",
       " 'WSJ920306-0079': 0.9289214,\n",
       " 'WSJ920302-0055': 0.92858034,\n",
       " 'WSJ920108-0042': 0.92368937}"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(eval_queries_head_top_50[51].items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920110-0094': 0.64772415,\n",
       " 'WSJ920228-0191': 0.61990196,\n",
       " 'WSJ920116-0130': 0.606834,\n",
       " 'WSJ920227-0147': 0.6032207,\n",
       " 'WSJ920306-0058': 0.58715224,\n",
       " 'WSJ920218-0155': 0.56357586,\n",
       " 'WSJ920317-0149': 0.56099534,\n",
       " 'WSJ920227-0058': 0.5549741,\n",
       " 'WSJ920108-0164': 0.5498039,\n",
       " 'WSJ920302-0119': 0.5485358}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(list(eval_queries_body_top_50[51].items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rankear con BM25 sobre los top-50 documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from math import log\n",
    "\n",
    "k1 = 1.2\n",
    "k2 = 100\n",
    "b = 0.75\n",
    "R = 0.0\n",
    "\n",
    "\n",
    "def score_BM25(n, f, qf, r, N, dl, avdl):\n",
    "    K = compute_K(dl, avdl)\n",
    "    first = log( ( (r + 0.5) / (R - r + 0.5) ) / ( (n - r + 0.5) / (N - n - R + r + 0.5)) )\n",
    "    second = ((k1 + 1) * f) / (K + f)\n",
    "    third = ((k2+1) * qf) / (k2 + qf)\n",
    "    return first * second * third\n",
    "\n",
    "def compute_K(dl, avdl):\n",
    "    return k1 * ((1-b) + b * (float(dl)/float(avdl)) )\n",
    "\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, queries, corpus, candidate_docs):\n",
    "        self.query_dict = queries\n",
    "        self.index, self.dlt = build_data_structures(corpus)\n",
    "        self.candidates = candidate_docs\n",
    "\n",
    "    def run(self):\n",
    "        results = dict()\n",
    "        for q_id, query in self.query_dict.items():\n",
    "            results[q_id] = self.run_query(query, q_id, self.candidates)\n",
    "        return results\n",
    "\n",
    "    def run_query(self, query, query_id, candidates_to_be_rel):\n",
    "        query_result = dict()\n",
    "        for term in query:\n",
    "            if term in self.index:\n",
    "                # retrieve index entry\n",
    "                doc_dict = self.index[term]\n",
    "                # for each document and its word frequency\n",
    "                for docid, freq in doc_dict.items():\n",
    "                    # Calcular y agregar score sólo si el documento está en el top-n de los\n",
    "                    # recuperados con AWE\n",
    "                    if docid in candidates_to_be_rel[query_id]:\n",
    "                        score = score_BM25(\n",
    "                            n=len(doc_dict),\n",
    "                            f=freq,\n",
    "                            qf=1,\n",
    "                            r=0,\n",
    "                            N=len(self.dlt),\n",
    "                            dl=self.dlt.get_length(docid),\n",
    "                            avdl=self.dlt.get_average_length()\n",
    "                        ) # calculate score\n",
    "                        if docid in query_result: #this document has already been scored once\n",
    "                            query_result[docid] += score\n",
    "                        else:\n",
    "                            query_result[docid] = score\n",
    "        return query_result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propuesta: procesar consultas sobre los títulos y los cuerpos de los documentos\n",
    "\n",
    "Procesar las consultas de `q_list` sobre los corpus de los títulos `corpus_h` y los cuerpos `corpus_b` y combinar los resultados ponderando los scores usando el parámetro `p`:\n",
    "\n",
    "\\begin{align}\n",
    "score(q) = p \\cdot score_{head}(q) + (1 - p) \\cdot score_{body}(q)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de procesador de consultas especial\n",
    "- evalúa sobre corpus_head y corpus_body automáticamente \n",
    "- es capaz de re-ponderar los puntajes al cambiar el parámetro p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryProcessorHeadBody:\n",
    "    def __init__(self, q_dict, corpus_h, corpus_b, candidates_h, candidates_b, p=0.1):\n",
    "        try:\n",
    "            assert p <= 1 and p >= 0\n",
    "        except Exception as e:\n",
    "            print('p debe estar en el rango [0, 1].')\n",
    "            return\n",
    "        self.results_head = QueryProcessor(\n",
    "            normalized_queries, \n",
    "            corpus_head, \n",
    "            candidates_h\n",
    "        ).run()\n",
    "        self.results_body = QueryProcessor(\n",
    "            normalized_queries, \n",
    "            corpus_body, \n",
    "            candidates_b\n",
    "        ).run()\n",
    "        self.p = p\n",
    "        self.scores = self.combine_results()\n",
    "\n",
    "    def change_weight(self, new_p=0.1):\n",
    "        try:\n",
    "            assert new_p <= 1 and new_p >= 0\n",
    "        except Exception as e:\n",
    "            print('p debe estar en el rango [0, 1].')\n",
    "            return\n",
    "        self.p = new_p\n",
    "        return self.combine_results()\n",
    "    \n",
    "    def combine_results(self):\n",
    "        results = dict()\n",
    "        for q_id, doc_scores in self.results_head.items():\n",
    "            results[q_id] = dict()\n",
    "            for doc_id, score_head in doc_scores.items():\n",
    "                results[q_id][doc_id] = self.p*score_head\n",
    "        for q_id, doc_scores in self.results_body.items():\n",
    "            for doc_id, score_body in doc_scores.items():\n",
    "                if doc_id in results:\n",
    "                    results[q_id][doc_id] += (1-self.p)*score_body\n",
    "                else:\n",
    "                    results[q_id][doc_id] = (1-self.p)*score_body\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de creación de la clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=0.1\n",
    "\n",
    "bm25_ranking = QueryProcessorHeadBody(\n",
    "    normalized_queries,\n",
    "    corpus_head,\n",
    "    corpus_body,\n",
    "    eval_queries_head_top_50,\n",
    "    eval_queries_body_top_50,\n",
    "    p   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920124-0156': 8.69706552569599,\n",
       " 'WSJ920108-0037': 7.28163328402616,\n",
       " 'WSJ920110-0094': 10.480623217742544,\n",
       " 'WSJ920114-0073': 3.841290222900916,\n",
       " 'WSJ920116-0130': 15.174131580075326,\n",
       " 'WSJ920211-0134': 5.9071985775913065,\n",
       " 'WSJ920213-0099': 4.238742985258622,\n",
       " 'WSJ920213-0011': 6.1039044005424055,\n",
       " 'WSJ920218-0155': 7.52804212173111,\n",
       " 'WSJ920221-0165': 5.4943545082425596,\n",
       " 'WSJ920225-0046': 7.923162483835888,\n",
       " 'WSJ920227-0147': 12.22135459482911,\n",
       " 'WSJ920227-0058': 7.302353369159894,\n",
       " 'WSJ920228-0191': 13.483855154974844,\n",
       " 'WSJ920302-0119': 10.953137060588778,\n",
       " 'WSJ920306-0058': 12.886097423355427,\n",
       " 'WSJ920316-0081': 7.743012408230292,\n",
       " 'WSJ920317-0149': 4.109767311410256,\n",
       " 'WSJ920103-0067': 2.721146218206719,\n",
       " 'WSJ920110-0069': 5.696390136671308,\n",
       " 'WSJ920113-0060': 5.230556072139496,\n",
       " 'WSJ920114-0012': 0.6615115841714074,\n",
       " 'WSJ920203-0042': 7.147498844460261,\n",
       " 'WSJ920204-0079': 2.7853049664372818,\n",
       " 'WSJ920210-0090': 6.656232330083361,\n",
       " 'WSJ920306-0152': 3.8421963187743975,\n",
       " 'WSJ920306-0080': 6.166706379016984,\n",
       " 'WSJ920311-0055': 4.069072940079203,\n",
       " 'WSJ920312-0129': 6.985646527974196,\n",
       " 'WSJ920318-0066': 6.283100786648249,\n",
       " 'WSJ920320-0029': 7.45911571286012}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_ranking.scores[51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algunas consultas de ejemplo\n",
    "\n",
    "- Se muestran los top-10 resultados de las tres primeras consultas del dataset, junto al puntaje BM25 evaluado para cada uno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_bm25_ranking = get_top_n(bm25_ranking.scores, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "`query_id` | top-10 docs. | BM25 Score\n",
       "--- | --- | ---\n",
       "51 | WSJ920116-0130<br>WSJ920228-0191<br>WSJ920306-0058<br>WSJ920227-0147<br>WSJ920302-0119<br>WSJ920110-0094<br>WSJ920124-0156<br>WSJ920225-0046<br>WSJ920316-0081<br>WSJ920218-0155 | 15.17<br>13.48<br>12.89<br>12.22<br>10.95<br>10.48<br>8.7<br>7.92<br>7.74<br>7.53\n",
       "52 | WSJ920220-0099<br>WSJ920313-0015<br>WSJ920319-0062<br>WSJ920225-0080<br>WSJ920320-0115<br>WSJ920129-0169<br>WSJ920114-0114<br>WSJ920203-0038<br>WSJ920221-0125<br>WSJ920210-0070 | 18.39<br>17.43<br>16.74<br>14.1<br>13.36<br>10.85<br>10.4<br>10.33<br>9.25<br>8.44\n",
       "53 | WSJ920122-0108<br>WSJ920129-0014<br>WSJ920221-0042<br>WSJ920220-0012<br>WSJ920131-0083<br>WSJ920225-0027<br>WSJ920312-0009<br>WSJ920316-0086<br>WSJ920205-0055<br>WSJ920318-0157 | 8.94<br>5.9<br>5.81<br>5.8<br>5.34<br>5.28<br>5.25<br>4.2<br>4.04<br>4.03\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "table = '`query_id` | top-10 docs. | BM25 Score\\n'\n",
    "table += '--- | --- | ---\\n'\n",
    "table += '51 | '+'<br>'.join([doc_id for doc_id in top_10_bm25_ranking[51].keys()])+' | '+'<br>'.join([str(round(doc_id, 2)) for doc_id in top_10_bm25_ranking[51].values()])+'\\n'\n",
    "table += '52 | '+'<br>'.join([doc_id for doc_id in top_10_bm25_ranking[52].keys()])+' | '+'<br>'.join([str(round(doc_id, 2)) for doc_id in top_10_bm25_ranking[52].values()])+'\\n'\n",
    "table += '53 | '+'<br>'.join([doc_id for doc_id in top_10_bm25_ranking[53].keys()])+' | '+'<br>'.join([str(round(doc_id, 2)) for doc_id in top_10_bm25_ranking[53].values()])+'\\n'\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A continuación se obtienen las métricas de precision y recall para los top-10 documentos resultantes de cada consulta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cargar relevancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha cargado qrels.51-100.disk1.disk2.part1\n",
      "Se ha cargado qrels.51-100.disk1.disk2.part2\n",
      "Se ha cargado qrels.51-100.disk1.disk2.part3\n",
      "Se ha cargado qrels.51-100.disk1.disk2.part4\n",
      "Se ha cargado qrels.51-100.disk1.disk2.part5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "qrels = dict()\n",
    "\n",
    "for i in range(1, 6):\n",
    "    with open(os.path.join('data', 'qrels.51-100.disk1.disk2.part'+str(i)), 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            if 'WSJ92' in line:\n",
    "                splitted = line.split(' ')\n",
    "                query_id = int(splitted[0])\n",
    "                doc_id = splitted[2]\n",
    "                is_rel = int(splitted[3])\n",
    "                if query_id not in qrels: qrels[query_id] = dict()\n",
    "                qrels[query_id][doc_id] = is_rel\n",
    "        print('Se ha cargado qrels.51-100.disk1.disk2.part'+str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chequear correctitud de carga de relevancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WSJ920108-0037': 0,\n",
       " 'WSJ920109-0101': 0,\n",
       " 'WSJ920110-0067': 0,\n",
       " 'WSJ920110-0069': 0,\n",
       " 'WSJ920110-0094': 1,\n",
       " 'WSJ920113-0060': 0,\n",
       " 'WSJ920114-0054': 0,\n",
       " 'WSJ920114-0073': 1,\n",
       " 'WSJ920115-0015': 0,\n",
       " 'WSJ920116-0018': 1,\n",
       " 'WSJ920116-0047': 0,\n",
       " 'WSJ920116-0080': 0,\n",
       " 'WSJ920116-0130': 1,\n",
       " 'WSJ920121-0016': 0,\n",
       " 'WSJ920121-0151': 0,\n",
       " 'WSJ920122-0161': 0,\n",
       " 'WSJ920124-0156': 0,\n",
       " 'WSJ920128-0088': 1,\n",
       " 'WSJ920129-0082': 0,\n",
       " 'WSJ920203-0175': 0,\n",
       " 'WSJ920211-0134': 0,\n",
       " 'WSJ920211-0165': 0,\n",
       " 'WSJ920212-0034': 0,\n",
       " 'WSJ920213-0011': 0,\n",
       " 'WSJ920213-0030': 0,\n",
       " 'WSJ920213-0099': 0,\n",
       " 'WSJ920218-0155': 0,\n",
       " 'WSJ920225-0046': 0,\n",
       " 'WSJ920226-0072': 0,\n",
       " 'WSJ920227-0058': 0,\n",
       " 'WSJ920227-0147': 1,\n",
       " 'WSJ920228-0191': 1,\n",
       " 'WSJ920302-0119': 1,\n",
       " 'WSJ920303-0065': 0,\n",
       " 'WSJ920303-0073': 0,\n",
       " 'WSJ920304-0144': 0,\n",
       " 'WSJ920306-0058': 1,\n",
       " 'WSJ920306-0080': 0,\n",
       " 'WSJ920312-0029': 0,\n",
       " 'WSJ920313-0135': 0,\n",
       " 'WSJ920317-0149': 0,\n",
       " 'WSJ920319-0151': 0,\n",
       " 'WSJ920320-0188': 0}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qrels[51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir función que obtiene precision, recall para cada consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_results(rankings, q_rels):\n",
    "    top_10_bm25_ranking = rankings\n",
    "    qrels = q_rels\n",
    "    final_results = dict()\n",
    "    sum_precision = 0\n",
    "    non_null_precisions = 0\n",
    "    sum_recall = 0\n",
    "    non_null_recalls = 0\n",
    "\n",
    "    for query_id, ranking in top_10_bm25_ranking.items():\n",
    "        final_results[query_id] = dict()\n",
    "        final_results[query_id]['ranking'] = ranking\n",
    "        number_of_true_relevants = sum(qrels[query_id].values())\n",
    "        final_results[query_id]['number_relevants'] = number_of_true_relevants\n",
    "        number_of_selected_elements = len(ranking)\n",
    "        #print('Query {}: {} docs in top-10'.format(query_id, number_of_selected_elements))\n",
    "        correctly_selected = 0\n",
    "        wrongly_selected = 0\n",
    "        no_relevance_info = 0\n",
    "        for doc_id, doc_rank in ranking.items():\n",
    "            if doc_id in qrels[query_id]:\n",
    "                if qrels[query_id][doc_id] == 1:\n",
    "                    correctly_selected += 1\n",
    "                elif qrels[query_id][doc_id] == 0:\n",
    "                    wrongly_selected += 1\n",
    "            else:\n",
    "                no_relevance_info += 1\n",
    "        final_results[query_id]['correct'] = correctly_selected\n",
    "        final_results[query_id]['incorrect'] = wrongly_selected\n",
    "        final_results[query_id]['no_info'] = no_relevance_info\n",
    "\n",
    "        # Calcular precision y recall\n",
    "        # precision = # of correctly selected elements / # of all selected elements\n",
    "        # recall = # of correctly selected elements / # of positive elements\n",
    "\n",
    "        if number_of_selected_elements != 0: \n",
    "            final_results[query_id]['precision'] = correctly_selected/number_of_selected_elements\n",
    "            sum_precision += correctly_selected/number_of_selected_elements\n",
    "            non_null_precisions += 1\n",
    "        else: final_results[query_id]['precision'] = None\n",
    "        if number_of_true_relevants != 0: \n",
    "            final_results[query_id]['recall'] = correctly_selected/number_of_true_relevants\n",
    "            sum_recall += correctly_selected/number_of_true_relevants\n",
    "            non_null_recalls += 1\n",
    "        else: final_results[query_id]['recall'] = None\n",
    "    avg_precision = sum_precision/non_null_precisions\n",
    "    avg_recall = sum_recall/non_null_recalls\n",
    "    #print('avg_precision = sum_precision/non_null_precisions: {} = {}/{}'.format(avg_precision,sum_precision,non_null_precisions))\n",
    "    #print('avg_recall = sum_recall/non_null_recalls: {} = {}/{}'.format(avg_recall,sum_recall,non_null_recalls))\n",
    "    return final_results, avg_precision, avg_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición de función que genera una tabla de resumen para cada consulta evaluada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_table(results, p):\n",
    "\n",
    "    from IPython.display import display, Markdown\n",
    "\n",
    "    # precision & recall @ top-10\n",
    "\n",
    "    table = '`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\\n'\n",
    "    table += '--- | --- | --- | --- | --- | --- | ---\\n'\n",
    "    for q_id, result_dict in final_results.items():\n",
    "        precision = result_dict['precision']\n",
    "        if precision is None: precision = 'N/A'\n",
    "        else: precision = round(precision, 2)\n",
    "        recall = result_dict['recall']\n",
    "        if recall is None: recall = 'N/A'\n",
    "        else: recall = round(recall, 2)\n",
    "        table += '{} | {} | {} | {} | {} | {} | {}\\n'.format(q_id, precision, recall, result_dict['number_relevants'], result_dict['correct'], result_dict['incorrect'], result_dict['no_info'])\n",
    "\n",
    "    display(Markdown('## p='+str(p)+': Precision & recall @ top-10'))\n",
    "    display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observar cómo varía el precision y recall al cambiar el parámetro p\n",
    "\n",
    "- p in [0.1, 0.3, 0.5, 0.7, 0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## p=0.1: Precision & recall @ top-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\n",
       "--- | --- | --- | --- | --- | --- | ---\n",
       "51 | 0.6 | 0.67 | 9 | 6 | 3 | 1\n",
       "52 | 0.7 | 0.64 | 11 | 7 | 1 | 2\n",
       "53 | 0.0 | 0.0 | 9 | 0 | 2 | 8\n",
       "54 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "55 | 0.2 | 0.29 | 7 | 2 | 2 | 6\n",
       "56 | 0.4 | 0.22 | 18 | 4 | 2 | 4\n",
       "57 | 0.8 | 0.67 | 12 | 8 | 0 | 2\n",
       "58 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "59 | 0.0 | 0.0 | 3 | 0 | 2 | 8\n",
       "60 | 0.1 | 0.25 | 4 | 1 | 3 | 6\n",
       "61 | 0.1 | 1.0 | 1 | 1 | 6 | 3\n",
       "62 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "63 | 0.0 | N/A | 0 | 0 | 4 | 6\n",
       "64 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "65 | 0.1 | 0.33 | 3 | 1 | 2 | 7\n",
       "66 | 0.0 | 0.0 | 1 | 0 | 1 | 9\n",
       "67 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "68 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "69 | 0.0 | N/A | 0 | 0 | 0 | 10\n",
       "70 | 0.0 | N/A | 0 | 0 | 1 | 0\n",
       "73 | 0.1 | 0.11 | 9 | 1 | 3 | 6\n",
       "74 | 0.0 | 0.0 | 18 | 0 | 2 | 8\n",
       "75 | 0.0 | 0.0 | 6 | 0 | 0 | 5\n",
       "76 | 0.5 | 0.56 | 9 | 5 | 3 | 2\n",
       "77 | N/A | N/A | 0 | 0 | 0 | 0\n",
       "78 | N/A | 0.0 | 2 | 0 | 0 | 0\n",
       "79 | 0.0 | 0.0 | 4 | 0 | 2 | 8\n",
       "80 | 0.0 | N/A | 0 | 0 | 8 | 2\n",
       "81 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "82 | 0.3 | 0.09 | 32 | 3 | 1 | 6\n",
       "83 | 0.1 | 0.11 | 9 | 1 | 1 | 8\n",
       "84 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "85 | 0.3 | 0.21 | 14 | 3 | 2 | 5\n",
       "86 | 0.0 | 0.0 | 5 | 0 | 8 | 2\n",
       "87 | 0.1 | 0.09 | 11 | 1 | 0 | 9\n",
       "88 | 0.0 | 0.0 | 4 | 0 | 3 | 7\n",
       "89 | 0.0 | 0.0 | 3 | 0 | 9 | 1\n",
       "90 | 0.6 | 0.35 | 17 | 6 | 4 | 0\n",
       "91 | 0.0 | N/A | 0 | 0 | 5 | 5\n",
       "92 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "93 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "94 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "95 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "96 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n",
       "97 | 0.3 | 0.3 | 10 | 3 | 4 | 3\n",
       "98 | 0.1 | 0.06 | 18 | 1 | 3 | 6\n",
       "99 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "100 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## p=0.3: Precision & recall @ top-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\n",
       "--- | --- | --- | --- | --- | --- | ---\n",
       "51 | 0.6 | 0.67 | 9 | 6 | 3 | 1\n",
       "52 | 0.7 | 0.64 | 11 | 7 | 1 | 2\n",
       "53 | 0.0 | 0.0 | 9 | 0 | 2 | 8\n",
       "54 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "55 | 0.2 | 0.29 | 7 | 2 | 2 | 6\n",
       "56 | 0.4 | 0.22 | 18 | 4 | 2 | 4\n",
       "57 | 0.8 | 0.67 | 12 | 8 | 0 | 2\n",
       "58 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "59 | 0.0 | 0.0 | 3 | 0 | 2 | 8\n",
       "60 | 0.1 | 0.25 | 4 | 1 | 3 | 6\n",
       "61 | 0.1 | 1.0 | 1 | 1 | 6 | 3\n",
       "62 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "63 | 0.0 | N/A | 0 | 0 | 4 | 6\n",
       "64 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "65 | 0.1 | 0.33 | 3 | 1 | 2 | 7\n",
       "66 | 0.0 | 0.0 | 1 | 0 | 1 | 9\n",
       "67 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "68 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "69 | 0.0 | N/A | 0 | 0 | 0 | 10\n",
       "70 | 0.0 | N/A | 0 | 0 | 1 | 0\n",
       "73 | 0.1 | 0.11 | 9 | 1 | 3 | 6\n",
       "74 | 0.0 | 0.0 | 18 | 0 | 2 | 8\n",
       "75 | 0.0 | 0.0 | 6 | 0 | 0 | 5\n",
       "76 | 0.5 | 0.56 | 9 | 5 | 3 | 2\n",
       "77 | N/A | N/A | 0 | 0 | 0 | 0\n",
       "78 | N/A | 0.0 | 2 | 0 | 0 | 0\n",
       "79 | 0.0 | 0.0 | 4 | 0 | 2 | 8\n",
       "80 | 0.0 | N/A | 0 | 0 | 8 | 2\n",
       "81 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "82 | 0.3 | 0.09 | 32 | 3 | 1 | 6\n",
       "83 | 0.1 | 0.11 | 9 | 1 | 1 | 8\n",
       "84 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "85 | 0.3 | 0.21 | 14 | 3 | 2 | 5\n",
       "86 | 0.0 | 0.0 | 5 | 0 | 8 | 2\n",
       "87 | 0.1 | 0.09 | 11 | 1 | 0 | 9\n",
       "88 | 0.0 | 0.0 | 4 | 0 | 3 | 7\n",
       "89 | 0.0 | 0.0 | 3 | 0 | 9 | 1\n",
       "90 | 0.6 | 0.35 | 17 | 6 | 4 | 0\n",
       "91 | 0.0 | N/A | 0 | 0 | 5 | 5\n",
       "92 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "93 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "94 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "95 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "96 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n",
       "97 | 0.3 | 0.3 | 10 | 3 | 4 | 3\n",
       "98 | 0.1 | 0.06 | 18 | 1 | 3 | 6\n",
       "99 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "100 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## p=0.5: Precision & recall @ top-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\n",
       "--- | --- | --- | --- | --- | --- | ---\n",
       "51 | 0.6 | 0.67 | 9 | 6 | 3 | 1\n",
       "52 | 0.7 | 0.64 | 11 | 7 | 1 | 2\n",
       "53 | 0.0 | 0.0 | 9 | 0 | 2 | 8\n",
       "54 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "55 | 0.2 | 0.29 | 7 | 2 | 2 | 6\n",
       "56 | 0.4 | 0.22 | 18 | 4 | 2 | 4\n",
       "57 | 0.8 | 0.67 | 12 | 8 | 0 | 2\n",
       "58 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "59 | 0.0 | 0.0 | 3 | 0 | 2 | 8\n",
       "60 | 0.1 | 0.25 | 4 | 1 | 3 | 6\n",
       "61 | 0.1 | 1.0 | 1 | 1 | 6 | 3\n",
       "62 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "63 | 0.0 | N/A | 0 | 0 | 4 | 6\n",
       "64 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "65 | 0.1 | 0.33 | 3 | 1 | 2 | 7\n",
       "66 | 0.0 | 0.0 | 1 | 0 | 1 | 9\n",
       "67 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "68 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "69 | 0.0 | N/A | 0 | 0 | 0 | 10\n",
       "70 | 0.0 | N/A | 0 | 0 | 1 | 0\n",
       "73 | 0.1 | 0.11 | 9 | 1 | 3 | 6\n",
       "74 | 0.0 | 0.0 | 18 | 0 | 2 | 8\n",
       "75 | 0.0 | 0.0 | 6 | 0 | 0 | 5\n",
       "76 | 0.5 | 0.56 | 9 | 5 | 3 | 2\n",
       "77 | N/A | N/A | 0 | 0 | 0 | 0\n",
       "78 | N/A | 0.0 | 2 | 0 | 0 | 0\n",
       "79 | 0.0 | 0.0 | 4 | 0 | 2 | 8\n",
       "80 | 0.0 | N/A | 0 | 0 | 8 | 2\n",
       "81 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "82 | 0.3 | 0.09 | 32 | 3 | 1 | 6\n",
       "83 | 0.1 | 0.11 | 9 | 1 | 1 | 8\n",
       "84 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "85 | 0.3 | 0.21 | 14 | 3 | 2 | 5\n",
       "86 | 0.0 | 0.0 | 5 | 0 | 8 | 2\n",
       "87 | 0.1 | 0.09 | 11 | 1 | 0 | 9\n",
       "88 | 0.0 | 0.0 | 4 | 0 | 3 | 7\n",
       "89 | 0.0 | 0.0 | 3 | 0 | 9 | 1\n",
       "90 | 0.6 | 0.35 | 17 | 6 | 4 | 0\n",
       "91 | 0.0 | N/A | 0 | 0 | 5 | 5\n",
       "92 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "93 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "94 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "95 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "96 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n",
       "97 | 0.3 | 0.3 | 10 | 3 | 4 | 3\n",
       "98 | 0.1 | 0.06 | 18 | 1 | 3 | 6\n",
       "99 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "100 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## p=0.7: Precision & recall @ top-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\n",
       "--- | --- | --- | --- | --- | --- | ---\n",
       "51 | 0.6 | 0.67 | 9 | 6 | 3 | 1\n",
       "52 | 0.7 | 0.64 | 11 | 7 | 1 | 2\n",
       "53 | 0.0 | 0.0 | 9 | 0 | 2 | 8\n",
       "54 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "55 | 0.2 | 0.29 | 7 | 2 | 2 | 6\n",
       "56 | 0.4 | 0.22 | 18 | 4 | 2 | 4\n",
       "57 | 0.8 | 0.67 | 12 | 8 | 0 | 2\n",
       "58 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "59 | 0.0 | 0.0 | 3 | 0 | 2 | 8\n",
       "60 | 0.1 | 0.25 | 4 | 1 | 3 | 6\n",
       "61 | 0.1 | 1.0 | 1 | 1 | 6 | 3\n",
       "62 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "63 | 0.0 | N/A | 0 | 0 | 4 | 6\n",
       "64 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "65 | 0.1 | 0.33 | 3 | 1 | 2 | 7\n",
       "66 | 0.0 | 0.0 | 1 | 0 | 1 | 9\n",
       "67 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "68 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "69 | 0.0 | N/A | 0 | 0 | 0 | 10\n",
       "70 | 0.0 | N/A | 0 | 0 | 1 | 0\n",
       "73 | 0.1 | 0.11 | 9 | 1 | 3 | 6\n",
       "74 | 0.0 | 0.0 | 18 | 0 | 2 | 8\n",
       "75 | 0.0 | 0.0 | 6 | 0 | 0 | 5\n",
       "76 | 0.5 | 0.56 | 9 | 5 | 3 | 2\n",
       "77 | N/A | N/A | 0 | 0 | 0 | 0\n",
       "78 | N/A | 0.0 | 2 | 0 | 0 | 0\n",
       "79 | 0.0 | 0.0 | 4 | 0 | 2 | 8\n",
       "80 | 0.0 | N/A | 0 | 0 | 8 | 2\n",
       "81 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "82 | 0.3 | 0.09 | 32 | 3 | 1 | 6\n",
       "83 | 0.1 | 0.11 | 9 | 1 | 1 | 8\n",
       "84 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "85 | 0.3 | 0.21 | 14 | 3 | 2 | 5\n",
       "86 | 0.0 | 0.0 | 5 | 0 | 8 | 2\n",
       "87 | 0.1 | 0.09 | 11 | 1 | 0 | 9\n",
       "88 | 0.0 | 0.0 | 4 | 0 | 3 | 7\n",
       "89 | 0.0 | 0.0 | 3 | 0 | 9 | 1\n",
       "90 | 0.6 | 0.35 | 17 | 6 | 4 | 0\n",
       "91 | 0.0 | N/A | 0 | 0 | 5 | 5\n",
       "92 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "93 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "94 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "95 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "96 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n",
       "97 | 0.3 | 0.3 | 10 | 3 | 4 | 3\n",
       "98 | 0.1 | 0.06 | 18 | 1 | 3 | 6\n",
       "99 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "100 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## p=0.9: Precision & recall @ top-10"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`query_id` | *Precision*@top-10 | *Recall*@top-10 | # of rel. Docs | Correct@top-10 | Incorrect@top-10 | No rel. Info@top-10\n",
       "--- | --- | --- | --- | --- | --- | ---\n",
       "51 | 0.6 | 0.67 | 9 | 6 | 3 | 1\n",
       "52 | 0.7 | 0.64 | 11 | 7 | 1 | 2\n",
       "53 | 0.0 | 0.0 | 9 | 0 | 2 | 8\n",
       "54 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "55 | 0.2 | 0.29 | 7 | 2 | 2 | 6\n",
       "56 | 0.4 | 0.22 | 18 | 4 | 2 | 4\n",
       "57 | 0.8 | 0.67 | 12 | 8 | 0 | 2\n",
       "58 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "59 | 0.0 | 0.0 | 3 | 0 | 2 | 8\n",
       "60 | 0.1 | 0.25 | 4 | 1 | 3 | 6\n",
       "61 | 0.1 | 1.0 | 1 | 1 | 6 | 3\n",
       "62 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "63 | 0.0 | N/A | 0 | 0 | 4 | 6\n",
       "64 | 0.0 | N/A | 0 | 0 | 3 | 7\n",
       "65 | 0.1 | 0.33 | 3 | 1 | 2 | 7\n",
       "66 | 0.0 | 0.0 | 1 | 0 | 1 | 9\n",
       "67 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "68 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "69 | 0.0 | N/A | 0 | 0 | 0 | 10\n",
       "70 | 0.0 | N/A | 0 | 0 | 1 | 0\n",
       "73 | 0.1 | 0.11 | 9 | 1 | 3 | 6\n",
       "74 | 0.0 | 0.0 | 18 | 0 | 2 | 8\n",
       "75 | 0.0 | 0.0 | 6 | 0 | 0 | 5\n",
       "76 | 0.5 | 0.56 | 9 | 5 | 3 | 2\n",
       "77 | N/A | N/A | 0 | 0 | 0 | 0\n",
       "78 | N/A | 0.0 | 2 | 0 | 0 | 0\n",
       "79 | 0.0 | 0.0 | 4 | 0 | 2 | 8\n",
       "80 | 0.0 | N/A | 0 | 0 | 8 | 2\n",
       "81 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "82 | 0.3 | 0.09 | 32 | 3 | 1 | 6\n",
       "83 | 0.1 | 0.11 | 9 | 1 | 1 | 8\n",
       "84 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "85 | 0.3 | 0.21 | 14 | 3 | 2 | 5\n",
       "86 | 0.0 | 0.0 | 5 | 0 | 8 | 2\n",
       "87 | 0.1 | 0.09 | 11 | 1 | 0 | 9\n",
       "88 | 0.0 | 0.0 | 4 | 0 | 3 | 7\n",
       "89 | 0.0 | 0.0 | 3 | 0 | 9 | 1\n",
       "90 | 0.6 | 0.35 | 17 | 6 | 4 | 0\n",
       "91 | 0.0 | N/A | 0 | 0 | 5 | 5\n",
       "92 | 0.0 | 0.0 | 1 | 0 | 2 | 8\n",
       "93 | 0.0 | N/A | 0 | 0 | 1 | 9\n",
       "94 | 0.0 | 0.0 | 2 | 0 | 3 | 7\n",
       "95 | 0.0 | 0.0 | 3 | 0 | 1 | 9\n",
       "96 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n",
       "97 | 0.3 | 0.3 | 10 | 3 | 4 | 3\n",
       "98 | 0.1 | 0.06 | 18 | 1 | 3 | 6\n",
       "99 | 0.0 | N/A | 0 | 0 | 2 | 8\n",
       "100 | 0.1 | 0.2 | 5 | 1 | 2 | 7\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "average_presicion_recall_for_p = []\n",
    "for p in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "    bm25_ranking.change_weight(p)\n",
    "    top_10_bm25_ranking = get_top_n(bm25_ranking.scores, 10)\n",
    "    #pp.pprint(top_10_bm25_ranking[51])\n",
    "    final_results, avg_precision, avg_recall = get_final_results(top_10_bm25_ranking, qrels)\n",
    "    average_presicion_recall_for_p.append({'p': p, 'avg_precision': avg_precision, 'avg_recall': avg_recall})\n",
    "    print_table(final_results, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que, sin importar el valor de `p`, los resultados son bastante deficientes en términos de precision y recall. Este resultado no es de extrañar ya que, para la recuperación de información en texto, la cantidad de documentos relevantes es mucho menor a la cantidad de no relevantes. Una rápida mirada sobre la columna `# of rel. Docs` de las tablas generadas confirma que los documetnos relevantes para cada consulta no suelen superar los 10. Es necesario aplicar técnicas  adicionales al proceso que se ha realizado para mitigar este desbalance.\n",
    "\n",
    "A continuación se observa cómo el valor del ponderador `p` afectó la calidad de los resultados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Avg. Precision & recall para cada valor de ponderación p"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "`p` | *Avg. Precision* | *Avg. Recall*\n",
       "--- | --- | --- \n",
       "0.1 | 0.12 | 0.18 \n",
       "0.3 | 0.12 | 0.18 \n",
       "0.5 | 0.12 | 0.18 \n",
       "0.7 | 0.12 | 0.18 \n",
       "0.9 | 0.12 | 0.18 \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "# averaged precision & recall for each p\n",
    "\n",
    "table = '`p` | *Avg. Precision* | *Avg. Recall*\\n'\n",
    "table += '--- | --- | --- \\n'\n",
    "for result in average_presicion_recall_for_p:\n",
    "    table += '{} | {} | {} \\n'.format(result['p'],round(result['avg_precision'], 2),round(result['avg_recall'], 2))\n",
    "\n",
    "display(Markdown('## Avg. Precision & recall para cada valor de ponderación p'))\n",
    "display(Markdown(table))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ponderación por `p` parece no afectar al precision y recall en absoluto. Se chequea cuáles son los documentos en el top-10 en común que retornan las evaluaciones sobre `corpus_body` y `corpus_head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_id=51\t1 docs. en común\n",
      "query_id=52\t4 docs. en común\n",
      "query_id=53\t0 docs. en común\n",
      "query_id=54\t3 docs. en común\n",
      "query_id=55\t17 docs. en común\n",
      "query_id=56\t4 docs. en común\n",
      "query_id=57\t4 docs. en común\n",
      "query_id=58\t0 docs. en común\n",
      "query_id=59\t0 docs. en común\n",
      "query_id=60\t2 docs. en común\n",
      "query_id=61\t0 docs. en común\n",
      "query_id=62\t0 docs. en común\n",
      "query_id=63\t0 docs. en común\n",
      "query_id=64\t0 docs. en común\n",
      "query_id=65\t3 docs. en común\n",
      "query_id=66\t2 docs. en común\n",
      "query_id=67\t1 docs. en común\n",
      "query_id=68\t1 docs. en común\n",
      "query_id=69\t0 docs. en común\n",
      "query_id=70\t0 docs. en común\n",
      "query_id=73\t1 docs. en común\n",
      "query_id=74\t2 docs. en común\n",
      "query_id=75\t0 docs. en común\n",
      "query_id=76\t0 docs. en común\n",
      "query_id=77\t0 docs. en común\n",
      "query_id=78\t0 docs. en común\n",
      "query_id=79\t1 docs. en común\n",
      "query_id=80\t3 docs. en común\n",
      "query_id=81\t1 docs. en común\n",
      "query_id=82\t0 docs. en común\n",
      "query_id=83\t0 docs. en común\n",
      "query_id=84\t0 docs. en común\n",
      "query_id=85\t0 docs. en común\n",
      "query_id=86\t6 docs. en común\n",
      "query_id=87\t0 docs. en común\n",
      "query_id=88\t8 docs. en común\n",
      "query_id=89\t1 docs. en común\n",
      "query_id=90\t12 docs. en común\n",
      "query_id=91\t1 docs. en común\n",
      "query_id=92\t1 docs. en común\n",
      "query_id=93\t0 docs. en común\n",
      "query_id=94\t3 docs. en común\n",
      "query_id=95\t1 docs. en común\n",
      "query_id=96\t0 docs. en común\n",
      "query_id=97\t1 docs. en común\n",
      "query_id=98\t0 docs. en común\n",
      "query_id=99\t0 docs. en común\n",
      "query_id=100\t3 docs. en común\n"
     ]
    }
   ],
   "source": [
    "for q_id, doc_scores in bm25_ranking.results_head.items():\n",
    "    print('query_id={}\\t{} docs. en común'.format(q_id, len(set(doc_scores.keys()).intersection(set( bm25_ranking.results_body[q_id].keys())))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por lo tanto, la razón de que el ponderador `p` no tiene efectos en precision y recall, es que las evaluaciones de las consultas sobre los títulos y los cuerpos por separados entregan conjuntos de documentos demasiado distintos, causando poca probabilidad de realizar cambios significativos al momento de combinar los resultados. Se asumió incorrectamente que los documentos retornados por la consulta evaluada sobre los títulos estarían probablemente también en los retornados al evaluar sobre los cuerpos.\n",
    "\n",
    "Se concluye que es posible reimplementar la ponderación, pero cambiando la metodología: por ejemplo, asignar score BM25 adicional por cada palabra que esté en el título del documento siendo rankeado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
